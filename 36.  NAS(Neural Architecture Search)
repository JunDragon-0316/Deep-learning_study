1. NAS란?
- AutoML (Automated Machine Learning) : 컴퓨터가 자동으로 머신 러닝을 해준다.
- What's in AutoML ? : NAS를 비롯하여 여러가지 기술이 포함되어 있다. NAS가 AutoML 분야에서 가장 주목받으면서,
  최근에는 NAS라고 하면 AutoML 전반을 모두 포함하는 경우가 많다.
  Training Data -> Feature Engineering -> Hyper Prameter Optimazation -> Neural Architecture Search
  Test Data -> Model -> Prediction
- NAS : 수행하는 과정은 Straight Forward하다. 각 과정의 연산 시간을 최소화 하는 것이 주된 목표이다.
  Search Space A -> Search Strategy -> Architecture -> Performance Estimation Strategy
                                                    <- Performance estimate of A
- Search Space : 서로 다른 Search Space를 가지는 두 Neural Network 구조와 Cell Search Space
- Search Strategy : 다양하다. 전통적인 EA, 최근에 효시 역할을 한 RL, 현 SOTA인 DARTS까지 있다.
  Reinforcement Learning(RL), Evolutionary Algorithm(EA), Differentiable Architecture Search(DARTS)
- Performance Estimation : 다양한 방법을 이용해 선택된 구조의 성능을 예측한다
  Lower fidelity estimates, Learning Curve Extraplation, Weight Inheritance / Network Morphisms
  One-Shot Models / Weight Sharing

2. 하이퍼 파라미터 최적화
- Parameters in Neural Nets : 최적화 방법 또는 다른 방법으로 학습 되는 변수 -> 학습 가능한 매개 변수 (Trainable Parameters)
  -> 매개 변수
  알고리즘 결과에 영향을 주지만, 처음 결정한 후 학습되지 않는 변수 -> 초 매개 변수 (Hyper Parameters)
- HyperParameters : 최적화 기법 ; 알고리즘 종류, 학습률, 모멘텀 계수, RMSProp 계수 등..
                    전결합 계층 ; 뉴런의 개수, Weight 초기화 방법, Bias 초기값, 활성 함수의 선택...
                    미니배치 학습법 : 배치크기, 총 Epoch 수, 손실 함수의 선택, 학습/검증 데이터셋 분류 방식..
                    이 외에도 선택이 필요한 모든 것이 초매개 변수이다.
- HyperParameters Optimization : Grid Search, Random Search, Bayesian Optimization(BO)중 BO를 많이 활용한다
- BO : Surrogate Model 확률모델, Acquisition Function 후보 추천 ; 현재까지 조사된 샘플로 목적함수를 추정하고, 그것을
기반으로 다음 후보 샘플을 추천하는 방식
- GP (Gaussian Process) : Surrogate Model에서 가장 많이 활용. Gaussian Distribution으로 근사한 것으로, 이 모델을 이용한
Regession을 GP Regession이라 한다. Observation에서 멀어질 수록 불확실성이 높은 특징이 있다.
- Multi-Armed Bandit (MAB) : Exploration(탐험) vs. Exploitation(정착)의 대표적인 문제

3. Auto Augmentation
- Data Augmentation : 일반적으로 이미지에 활용하는 기법 (Flip, Rotate, Crop, Cutout...)
- Auto Augment : NAS의 영향을 받아서 Google Brain에서 발표한 AUtomatic Data Augmentation 기법
  Original 데이터를 자동으로 Sub-policy1,2,3,4,5..등을 Invert, Solarize, AutoContrast, Euqalize ...등 으로 변형시키는것
- Overall Framework : RNN으로 구성된 Controller로 Strategy S를 추정하여 샘플링한다.
  Strategy S를 이용해 Chile Network를 학습한 결과로 정확도 R을 구하고, Controller를 Update한다.
- Search Space : Augmentataion 방법으로는 PIL(Pillow Image Library)에서 제공하는 Function을 사용 추가로
  Cutout, Sample Pairing 방법을 적용해 총 16개의 방법 채용함.
  Translate X/Y, Rotate, AutoContrast, Invert, Equalize, So-larize, Rosterize, Contrast, Color, Brightness
  Sharpness, Cutout, Sample Pairing, Shear X/y
  Reinforcement Learning 방법인 PPO를 이용해 최적화를 하였다.
- Results : SOTA라고 볼 수 있는 Cutout 기법 대비 좋은 성능을 보인다. 특히 Dataset의 크기가 작은 Reduced SVHN에서 
성능 개선이 두드러진다.

4. Activation Function
- Searching For Activation Function : ReLU를 뛰어 넘는 Activation Function을 찾기위한 연구로 Google Brain연구다
- Search Space : Unary function들과 Binary Function들을 미리 선정해 Serch Space구성 하여 최적화 Function을 찾는다.
- RNN Controller : Reinforcement Learning을 수행한다. 
    Binary -> Input1 -> Input2 -> Unary1 -> Unary2 -> Binary 반복 형태
- Top Novel Activations : 이 중 최고 성능을 나타낸 함수는 xσ(βx)이다. Swish로 명명되어 있다 
- Results : ReLU를 뛰어넘는 성능을 보여준다. TF2.1 기준 tf.nn.swish로 사용 가능하다.

5. 자동 모델 구조 최적화
- NASNet : Normal Cell과 REduction Cell로 나누고, 자주 쓰이는 Operation을 후보로 두었다.
 ImageNet에서 SOTA의 성능을 보여줌
- DARTS : Mixed Operation의 가중치를 이용해, Child network의 선택이 미분 가능하게 한다.
  GPU Hour 대비 매우 좋은 성능을 나타낸다. 
