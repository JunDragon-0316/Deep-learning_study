1. 다중 클래스 분류 (Multi-Class Classfication)
- 고양이가 맞니?(이진분류) -> 네 or 아니오
- 이게뭐니? (다중분류) -> 네 or 아니오
- 이진분류 에서는 '어떤 물체'인지 표현할 필요가 없으나, 다중분류에서는 '어떤물체'인지 표현해야 한다.

2. 정답을 어떻게 표현할 것인가? 원- 핫 인코딩
- One- Hot Encoding: 한 개의 값만 1이고, 나머지 값은 0 인 벡터로 표현한 기법
- 원 핫 인코딩된 벡터는 미리 정해둔 Table을 이용해 어떤 물체인지 알 수 있다.
- 희소표현( Sparse Vector): 대부분의 값이 0 이고 크기가 있는 값이 희소하게 나타나는 벡터
- 희소 표현을 이용해 벡터 전체를 표기하지 않고, 숫자 하나로 표현할 수 있다. 

3. 얕은 신경망을 이용한 다중클래스
- Softmax (a + b + c = 1) 확률분할
- 한가지 확률만 100% 이고 , 나머지는 0 % 인것이 정답 (=원 핫 인코딩)
- 실제 알고리즘 출력을 확률로 변환하기 위해 Softmax 함수를 사용한다.

4. 출력을 어떻게 계산할 것인가? Softmax Function
- softmax(x)i =  exi
                ∑jexj
- 각 입력이 지수함수를 정규화한것.
- 각 출력은 0~1 사이의 값을 가짐
- 모든 출력의 합은 반드시 1이 된다.
- 여러 경우의 수 중 한가지에 속할 '확률'을 표현한다.
- Softmax는 최종 출력단에서  N가지 범주로 분류하는 Multi Class Classification에 쓰인다.

5. Softmax(다중분류) VS. Sigmoid(이중분류)
- sigmoid는 하나의 입력을 0 으로 강제한 2-Class softmax 함수와 동일하다.
- 2가지 클래스를 구분하기 위해 1개의 입력을 받는다는 점에 주목해야 한다.
- softmax([x, 0])o =    ex     =    1 (sigmoid x)
                      ex + eo     1 + e-x
                      
6. 정답과 출력을 어떻게 비교할까 ? 교차 엔트로피 오차
- CEE E = - ∑yilogy(틸다)i
            i
- yi: 합습 데이터 정답의 i번쨰 요소 (원- 핫 인코딩)
- y(틸다)i : 학습 데이터 입력으로 추정한 출력의 i번째 요소
- 원 - 핫 인코딩으로 인해, 정답인 클래스에 대해서만 오차를 계산.
- 정확히 맞추면 0, 틀릴수록 오차가 무한히 증가하는 특징이 있다.
- 오차를 내는 과정에서 정답 클래스만 비교하지만, 다중 클래스 분류의 활성함수인 softmax 함수로
- 인해 다른 클래스에 대한 학습에도 영향을 준다.

