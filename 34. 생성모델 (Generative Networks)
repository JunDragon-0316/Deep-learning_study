1. 생성모델이란 ?
- 분별 모델 Discriminative Models : 입력 X가 특정x일 때 , 출력이 특정 Y일 확률을 각각 구한다
우리가 익히 배워오던 Classification 방법은 대부분 분별 모델이다.
Decision Boundary를 찾는 것이 목표, 샘플을 입력 받아 각 Class에 속할 확률을 계산
- 생성 모델 Generative Models : 출력 Y가 특정 y라고 가정했을때, 모든 X가 여기에 속할 확률을 구한다.
생성 모델의 특징은, 입력의 분포를 학습한다는 것이다. 입력의 분포를 어떻게 모델링 하느냐가 다를 뿐!
입력 샘플의 분포를 찾는 것이 목표, 각 Class에 대해 샘플이 속할 확률을 구해서 비교
- 생성모델의 활용
입력분포를 학습 -> 입력을 모사할 수 있는 능력이라고 할 수 있음
앞으로 배울 GAN, VAE 등을 이용해 심층 생성 모델이 할 수 있는 다양한 동작을 알아볼 것

2. 생성모델 애플리케이션
- Image-to-Image Translation (Pix2Pix): 다양한 입출력 관계를 학습할 수 있는 학습 모델로, 초창기에 GAN
을 알리는데 큰 역할을 했다.
- Image Style Transfer : 특히, 영상 스타일 전이 연구는 스마트폰 앱으로도 개발되어 대중에게 많이 알려졌다.
- 심층 얼굴 합성 (DeepFake) : 얼굴 합성의 수준이 사람이 알아채기 어려운 수준까지 좋아졌다.
최근에는 SNS상에서 무분별하게 쓰이면서 문제가 되고있다. 앞으로 다가올 사회 문제중 하나로 지목되고 있다.
- Pose Transfer : DeepFake 연구의 일환으로 춤이나 행동에 관련 합성이 가능하다.
- 문장- 영상 변환 (Trxt2Image) : 간단한 문장을 이해하고, 이것을 영상으로 변환하는 연구 분야

3. 생성 모델 Generative Models 활용 방법
- 생성모델을 어떻게 활용할 것인가에 따라, 구체적인 모델을 결정할 수 있다.
- 고양이인지 개인지 알고 싶다.
- 고양이가 아닌 개에게만 관심이 있다.
- 훼손된 고양이 샘플을 되살리고 싶다.(AE)
- 있음 직한 개 샘플을 만들고 싶다.(GAN)
- 개와 고양이의 Hybrid를 만들고 싶다.(VAE)
- 개 짖는 소리를 따라하고 싶다.(AR)

4. 생성모델 종류
- 자동회귀 모델 AR; Autoregressive Models : 자동회귀라고 번역되지만, 실질적인 의미는 자가회귀라고 보는것이 더 적절하다.
시간에 따라 변화하는 Random Process로서 이전n개 Time step의 자신의 값에 영향을 받는다.
- 자동 부호기 AE; Autoencoder : 자동부호기 역시 자가 부호기라고 보는 것이 좋다. 자기 자신의 Feature를 추출하는
기능을 갖추고 있다. Encoder 부분은 Representation Learning, Decoder부분은 Generative Model로 볼 수 있다.
- VAE ; Variational Autoencoder : VAE는 사실 AE를 변형해서 나온 구조는 아니다. 하지만 결과적으로 AE와 유사한 구조
가 되므로, AE에서 어떤 점이 다른 지 보면 이해하기 쉽다.
- GAN ; Generative Adversarial Networks : GAN은 Ian goodfellow 박사가 제안한, 흥미롭고 훌륭한 학습이다.
속이고자 하는 Generator(도둑)와 간파하고자 하는 Discriminator(경찰)를 함꼐 학습시켜 Generator의 성능을 향상시킨다.

5. GAN (Generative Adversarial Networks)
- 기계 학습 사상 가장 독창적인 구조로 평가받는 GAN
- z -> Generator -> 출력, 입력 -> Discriminator -> Real? Fack? 의 구조를 갖는다
- Why Adversarial? 둘의 경합은 왜 결과가 좋은가? 상상하지 못한 방법을 찾을 수 있기 떄문
- Mini-Max Problem  : min max E[log(D(x))+E[log(1-D(G(z))]
                       G   D            D(G(z)) -> Fake(0), D(x) -> Real(1)
  0에 가까운 값일수록 결과값이 좋은것 이다.
      Training Discriminator                Training Generator       
max E[log(D(x))+E[log(1-D(G(z))]    min E[log(D(x))+E[log(1-D(G(z))]
 D     Real(1)     Fake(0)           G                Better Fake
 D학습과 G학습을 번갈아 하면서, 서로에게 Insight를 제공하는 형태로 학습한다
- What is z vector? : z벡터는 G의 입력이 되는 값으로 ,Random Seed라고 볼 수 있다.
  학습 시에는 Random하게 다양한 값을 넣어서 넓은 Domain을 커버하도록 한다.
- A Little rick! : G의 성능이 좋지 않을 떄 학습이 잘 되지 않는 문제를 해결하기 위해 수식을 조금 변경해야 한다.
  min max E[log(D(x))-E[log(D(G(z))]
   G   D   
- Training Procedures : Discriminator 학습 : 1. 임의의 z 생성 -> 2. G(z)계산 -> 3. D학습(1~2 Epoch)
                        Generator학습 : 4. 임의의 z 생성 -> 5. G(z)계산 -> 6. G학습(1~2 Epoch) -> 7. 1~6 계속 반복
6. 자동회귀 모델 AR
- AR 모델을 이용한 Google DeepMind의 PixelCNN과 WaveNet등이 있다.
- AR Equations : 결국 p 개의 이전 샘플을 이용해 Linear Regression하여 현재 샘플을 예측하는 것과 동일하다
  AR(p)모델 : xt = c + ∑ φi xt-i+ εt 
  xt=RandomProcess, c=Constant(Bias), φi=모델파라미터, εt=white noise
- CNN Model은 AR모델과 비슷한 면이 있다.
- 일부 값을 Masking하여 사용하면 AR모델처럼 이전 값들만 참조할 수 있다.
- ResNet과 유사하게 Pre-Activation을 이용하여 Layer를 구성하고 있다.
- Pixel CNN : Unsupervised Learning 형태이므로 ,Autoencoder의 형태와 상당히 유사하다.
- 1-D WaveNet : AR의 본거지인 1-D Signal에 다시 Pixel CNN을 접목한것과 유사하다.
- Global Condition : 화자, 감정상태 등 한 문장을 생성하는 Global Condition을 설정할 수 있다.
- Local Condition : 문장의 Text 정보와 같은 Local Condition을 지정하여 학습할 수 있다.

7. VAE
- VAE : 입력 -> Encoder -> Mean Vector  μ                   -> Latent Variables z -> Decoder -> 출력
                        -> Standard Deviation Vector σ -> ε
- 임의로 영상을 생성할 경우, 인물영상 or 노이즈영상이 발생할 확률은 동일하다.
  Natural Image는 전체 영상 Domain 중에서 매우 Sparse하게 존재한다.
- Manifold Learning : 더 낮은 차원으로 (N > M)변환하는 것을 Embedding이라 하고, 이 Embedding Function을 학습하는 것
- KL Divergence : 두 확률 분포가 다른 정도를 나타내는 것이 목적이다. 
  거리(Distance)라고 부를 수는 없는데, 교환법칙이 성립하지 않기 때문이다.
- Evidence Lower Bound (ELBO) : Log-Likehood를 최대화 하고 싶다 (MLE)
- Interesting Result : 하나의 샘플과 다른 샘플 0을 평균으로 1을 표준편차를 따르는 가우시안기법을 따르는데
  그 영상의 네츄럴 이미지를 뽑아낼 수 있다.
  스마일링 벡터를 넣어주면 웃는 이미지, 빼주면 무표정, 선글라스를 넣으면 선글라스를 쓴 , 빼면 뺀 이미지가 나오는 효과가 있다.
  
8. 이미지 변환 모듈 (Pix2pix)
- 흥미로운 영상 변형 모델, 다양한 영상을 학습할 수 있는 모델
- Conditional GAN 구조를 채용. Discriminato의 입력으로 Generator 출력과 입력을 Pair로 함께 넣는 특징이 있다.
- Loss Function : GAN Loss에 L-1 Loss를 추가하여 Content Loss를 추가 하였다
- U-Net Architecture : U-Net구조를 채용하여 Encoder-Decoder 구조에 해상력을 더했다.
- Results W/ Different Losses : Loss별로 다른 결과가 나타난다. GAN의 단점을 L1 Loss가 커버하는걸 볼 수 있다.
    Discriminator의 Receptive Field에 따른 해상도 차이를 볼수 있다. 70x70 수준이면 적절하다고 본다.
- Interactive Demo : 다양한 데모도 제공함 http://affinelayer.com/pixsrv/  

9. Self-Attention For Generative Models
- Image Transformer : Google Brain에서 발표한 강력한 Generative Models이다. Self-Attention을 적극적으로
 활용하여 Convolution을 대체하였다.
 Local self-Attention : 기존의 Convolutional Layer를 self-Attention Layer로 교체하였다 RNN을 Transforme로 대체한
 것처럼 , CNN을 Image Transformer로 교체 한것. Learned Embedding등 Transformer에서 차용한 부분이 많다
 Positional Encoding : Transformer와 유사한 방식의 PE를 사용하였다.
 DropOut : 특정 Feature에 좌우되지 않게 하였다.
 Local 1D , 2D Attention : Memory-Efficient한 구현을 위해 Memory Block과 Query Block을 구분하였다
 아직 생성되지 않은 부분은 연산하지 않도록 Masking하여 속도를 높였다.
 Generation Result : 기존 AR 모델에 비해 성능이 향상 되었다.
 Super- Resolution Result : CelebA 데이터셋에서 실험한 결과. 디테일의 수준이 높아졌다.
 
10. 정량 지표
- Comparing Generative Models : 정량적 비교가 어렵다.
- Likelihood : VAE의 경우 Reconstruction이 가능하지만 수치적으로 비교가 어렵다.
- IS (Inception Score) : Pretrained Inception-v3 모델을 이용하여 Conditional label dist와 Marginal label dist
를 비교한다. 값은 클 수록 좋으며, 보통 1~3 정도 값을 가진다.
- FID (Frechet Inception Distance) : Pretrained Inception-v3모델의 pool3 layer 출력을 이용한다. 실제 영상과
생성된 영상에서 각 Statistics를 구한뒤 이를 비교한다 (작을수록 좋음)
 FID = ||μr - μg ||² + Tr(∑r + ∑g - 2(∑r∑g)½)

11. 응용하기 좋은 데이터 셋
- Basically Enerything : Unsupervised Learning이 가능한 특성 상 모든 데이터셋이 활용가능 하다
- CIFAR-10 : 32x32 컬러 이미지로 되어 있는 10가지 Class로 되어있는 Dataset. 생성 모델 학습에 많이 사용된다.
- CelebA : 수 많은 셀럽들의 얼굴데이터가 있어 다양한 목적으로 많이 사용되는 Dataset. Annotation을 이용하여 다양한 연구에 쓰인다
- STL-10 : ImageNet 데이터 셋을 이용해 CIFAR-10보다 고화질로 구성된 Dataset
- FFHQ (Flickr-Faces-HQ Dataset) : Flickr에서 수집된 고화질 얼굴 영상 모음으로, 연구 목적으로 공개된 Dataset

12. 관련 대회 소개
- FashionGen Challenge : ECCV 2018,ICCV 2019 workshop에서 발표했다. 패션업계에서 관심이 많다.
- Generative Dog Images : 2019 8월에 종료된 Competition이지만, 실험해 보며 참고해 볼 만 하다.
